\chapter{Generative Adversarial Networks}
\label{chap:chapter1}

\begin{chapterabstract}
	In this chapter, we propose an overview	 of the Generative Adversarial Networks \cite{Goodfellow2014} framework, some of its theoretical interpretations, as well as some of its variations and applications. We discuss the recent advances about \GANs
\end{chapterabstract}

\section{Generative Adversarial Networks}
Applications to image generation

GAN formulation, loss variations, JS/KL interpretation of the loss

Conditional GANs

Introduction to domain-transfer (Pix2Pix, CycleGAN) through removal of the random noise

\section{Limitations}
Image quality : Incremental enhancement through architecture, more data, ... 

Instability, catastrophic forgetting and the mode collapse problem

Trade-off image quality/diversity : Explanation through the loss term and distribution coverage

Black-box approach to conditioning, no tuning possible, no interpretability

\section{The GAN Zoo}

Enorme nombre de variantes de GANs

Taxonomie des approches GANs (pour s'éviter une liste des différents GANs)

Schéma pour définir les grandes familles de GAN (évoquer les AmbientGAN / UNIR)

Table des loss alternatives (f-divergences + transport optimal)


\section{A note on the  evaluation of generative models}

No good adhoc methods

Image quality : Inception distance + Fréchet inception distance, advantages

Conditioning : Direct evaluation (pixel-wise), Classifier accuracy, Projections (PCA, t-SNE)

Limitations of those metrics : need a pre-trained model


