@misc{Laloy2019,
abstract = {Global probabilistic inversion within the latent space learned by a Generative Adversarial Network (GAN) has been recently demonstrated. Compared to inversion on the original model space, using the latent space of a trained GAN can offer the following benefits: (1) the generated model proposals are geostatistically consistent with the prescribed prior training image (TI), and (2) the parameter space is reduced by orders of magnitude compared to the original model space. Nevertheless, exploring the learned latent space by state-of-the-art Markov chain Monte Carlo (MCMC) methods may still require a large computational effort. As an alternative, parameters in this latent space could possibly be optimized with much less computationally expensive gradient-based methods. This study shows that due to the typically highly nonlinear relationship between the latent space and the associated output space of a GAN, gradient-based deterministic inversion may fail even when considering a linear forward physical model. We tested two deterministic inversion approaches: a quasi-Newton gradient descent using the Adam algorithm and a Gaussâ€“Newton (GN) method that makes use of the Jacobian matrix calculated by finite-differencing. For a channelized binary TI and a synthetic linear crosshole ground penetrating radar (GPR) tomography problem involving 576 measurements with low noise, we observe that when allowing for a total of 10,000 iterations only 13{\%} of the gradient descent trials locate a solution that has the required data misfit. The tested GN inversion was unable to recover a solution with the appropriate data misfit. Our results suggest that deterministic inversion performance strongly depends on the inversion approach, starting model, true reference model, number of iterations and noise realization. In contrast, computationally-expensive probabilistic global optimization based on differential evolution always finds an appropriate solution.},
archivePrefix = {arXiv},
arxivId = {1812.09140},
author = {Laloy, Eric and Linde, Niklas and Ruffino, Cyprien and H{\'{e}}rault, Romain and Gasso, Gilles and Jacques, Diederik},
booktitle = {Computers and Geosciences},
doi = {10.1016/j.cageo.2019.104333},
eprint = {1812.09140},
issn = {00983004},
keywords = {Deep learning,Deterministic inversion,Generative adversarial networks (GANs),Geophysics,Non-linearity},
month = {dec},
pages = {104333},
publisher = {Elsevier Ltd},
title = {{Gradient-based deterministic inversion of geophysical data with generative adversarial networks: Is it feasible?}},
volume = {133},
year = {2019}
}
@article{Ruffino2019,
abstract = {Generative Adversarial Networks (GANs) have proven successful for unsupervised image generation. Several works extended GANs to image inpainting by conditioning the generation with parts of the image one wants to reconstruct. However, these methods have limitations in settings where only a small subset of the image pixels is known beforehand. In this paper, we study the effectiveness of conditioning GANs by adding an explicit regularization term to enforce pixel-wise conditions when very few pixel values are provided. In addition, we also investigate the influence of this regularization term on the quality of the generated images and the satisfaction of the conditions. Conducted experiments on MNIST and FashionMNIST show evidence that this regularization term allows for controlling the trade-off between quality of the generated images and constraint satisfaction.},
archivePrefix = {arXiv},
arxivId = {1911.00689},
author = {Ruffino, Cyprien and H{\'{e}}rault, Romain and Laloy, Eric and Gasso, Gilles},
eprint = {1911.00689},
file = {:home/cyprien/Documents/Mendeley/Pixel-wise Conditioning of Generative Adversarial Networks - 2019.pdf:pdf},
journal = {ESANN 2019 - Proceedings, 27th European Symposium on Artificial Neural Networks, Computational Intelligence and Machine Learning},
month = {nov},
pages = {25--30},
publisher = {ESANN (i6doc.com)},
title = {{Pixel-wise Conditioning of Generative Adversarial Networks}},
url = {http://arxiv.org/abs/1911.00689},
year = {2019}
}
@article{Ruffino2019a,
abstract = {Generative models have recently received renewed attention as a result of adversarial learning. Generative adversarial networks consist of samples generation model and a discrimination model able to distinguish between genuine and synthetic samples. In combination with convolutional (for the discriminator) and de-convolutional (for the generator) layers, they are particularly suitable for image generation, especially of natural scenes. However, the presence of fully connected layers adds global dependencies in the generated images. This may lead to high and global variations in the generated sample for small local variations in the input noise. In this work we propose to use architec-tures based on fully convolutional networks (including among others dilated layers), architectures specifically designed to generate globally ergodic images, that is images without global dependencies. Conducted experiments reveal that these architectures are well suited for generating natural textures such as geologic structures .},
archivePrefix = {arXiv},
arxivId = {1905.08613},
author = {Ruffino, Cyprien and H{\'{e}}rault, Romain and Laloy, Eric and Gasso, Gilles},
eprint = {1905.08613},
file = {:home/cyprien/Documents/Mendeley/Dilated Spatial Generative Adversarial Networks for Ergodic Image Generation - 2019.pdf:pdf},
month = {may},
title = {{Dilated Spatial Generative Adversarial Networks for Ergodic Image Generation}},
url = {http://arxiv.org/abs/1905.08613},
year = {2019}
}
@article{Ruffino2020,
author = {Ruffino, Cyprien and H{\'{e}}rault, Romain and Laloy, Eric and Gasso, Gilles},
doi = {10.1016/j.neucom.2019.11.116},
issn = {09252312},
journal = {Neurocomputing},
month = {apr},
publisher = {Elsevier},
title = {{Pixel-wise Conditioned Generative Adversarial Networks for Image Synthesis and Completion}},
url = {https://linkinghub.elsevier.com/retrieve/pii/S0925231220305154},
year = {2020}
}
